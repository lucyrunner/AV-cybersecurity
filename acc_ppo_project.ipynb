{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Cruise Control (ACC) with PPO and Adversarial Attacks\n",
    "\n",
    "This notebook contains the complete implementation of an Adaptive Cruise Control system using PPO reinforcement learning, along with adversarial attack methods (FGSM and OIA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ACCEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "    \n",
    "    # Physical constants\n",
    "    DT = 0.1    # time step (s)\n",
    "    TH = 1.5    # desired time headway (s)\n",
    "    D0 = 5.0    # standstill distance (m)\n",
    "    V_REF = 15.0    # target speed (m/s)\n",
    "    A_MIN = -3.5    # braking limit (m/s^2)\n",
    "    A_MAX = 2.0    # acceleration limit (m/s^2)\n",
    "    \n",
    "    # State space bounds (for Box space definition)\n",
    "    OBS_LOW = np.array([0.0, -30.0, 0.0], dtype=np.float32)\n",
    "    OBS_HIGH = np.array([200.0, 30.0, 40.0], dtype=np.float32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=self.OBS_LOW, \n",
    "            high=self.OBS_HIGH, \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([self.A_MIN], dtype=np.float32),\n",
    "            high=np.array([self.A_MAX], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Episode settings\n",
    "        self.max_steps = 400\n",
    "        \n",
    "        # State variables (will be initialized in reset)\n",
    "        self.x_ego = 0.0\n",
    "        self.x_lead = 0.0\n",
    "        self.v_ego = 0.0\n",
    "        self.v_lead = 0.0\n",
    "        self.a_ego = 0.0\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Lead vehicle deceleration profile (for testing scenarios)\n",
    "        self.lead_decel_active = False\n",
    "        self.lead_decel_start = None\n",
    "        self.lead_decel_duration = None\n",
    "        self.lead_decel_value = None\n",
    "        \n",
    "        # Attack interface: allows external override of observation for safety filter\n",
    "        self._safety_obs_override = None\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # Initialize state with small random variations\n",
    "        self.x_ego = 0.0\n",
    "        self.x_lead = 30.0 + self.np_random.uniform(-1.0, 1.0)\n",
    "        self.v_ego = self.V_REF - 0.5 + self.np_random.uniform(-0.2, 0.2)\n",
    "        self.v_lead = self.V_REF + self.np_random.uniform(-0.5, 0.5)\n",
    "        self.a_ego = 0.0\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Reset lead vehicle deceleration profile\n",
    "        self.lead_decel_active = False\n",
    "        self.lead_decel_start = None\n",
    "        self.lead_decel_duration = None\n",
    "        self.lead_decel_value = None\n",
    "        \n",
    "        # Clear attack override\n",
    "        self._safety_obs_override = None\n",
    "        \n",
    "        obs = self._get_obs()\n",
    "        return obs, {}\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        \"\"\"Return current observation [dx, dv, v]\"\"\"\n",
    "        dx = self.x_lead - self.x_ego\n",
    "        dv = self.v_lead - self.v_ego\n",
    "        v = self.v_ego\n",
    "        return np.array([dx, dv, v], dtype=np.float32)\n",
    "    \n",
    "    def set_safety_obs_for_filter(self, obs_adv):\n",
    "        self._safety_obs_override = np.array(obs_adv, dtype=np.float32)\n",
    "    \n",
    "    def _compute_safe_action(self, obs_for_filter):\n",
    "        dx, dv, v = obs_for_filter[0], obs_for_filter[1], obs_for_filter[2]\n",
    "        \n",
    "        numerator = dx - self.TH * v + (self.v_lead - v) * self.DT\n",
    "        denominator = self.TH * self.DT\n",
    "        \n",
    "        if denominator <= 0:\n",
    "            return self.A_MIN\n",
    "        \n",
    "        a_max_safe = numerator / denominator\n",
    "        return float(np.clip(a_max_safe, self.A_MIN, self.A_MAX))\n",
    "    \n",
    "    def _apply_safety_filter(self, action_rl):\n",
    "        # Determine which observation to use for safety filter\n",
    "        if self._safety_obs_override is not None:\n",
    "            obs_for_filter = self._safety_obs_override\n",
    "            self._safety_obs_override = None  # consume override\n",
    "        else:\n",
    "            obs_for_filter = self._get_obs()\n",
    "        \n",
    "        # Compute maximum safe action and clamp\n",
    "        a_max_safe = self._compute_safe_action(obs_for_filter)\n",
    "        a_safe = min(action_rl, a_max_safe)\n",
    "        a_safe = np.clip(a_safe, self.A_MIN, self.A_MAX)\n",
    "        \n",
    "        return float(a_safe)\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Extract scalar action\n",
    "        a_rl = float(action[0]) if isinstance(action, np.ndarray) else float(action)\n",
    "        \n",
    "        # Apply safety filter\n",
    "        a_safe = self._apply_safety_filter(a_rl)\n",
    "        \n",
    "        # Update ego vehicle (forward Euler integration)\n",
    "        self.x_ego += self.v_ego * self.DT + 0.5 * a_safe * self.DT ** 2\n",
    "        self.v_ego = np.clip(self.v_ego + a_safe * self.DT, 0.0, 100.0)\n",
    "        self.a_ego = a_safe\n",
    "        \n",
    "        # Update lead vehicle\n",
    "        if self.lead_decel_active:\n",
    "            t = self.current_step * self.DT\n",
    "            if self.lead_decel_start <= t < self.lead_decel_start + self.lead_decel_duration:\n",
    "                # Apply deceleration\n",
    "                self.v_lead = max(0.0, self.v_lead + self.lead_decel_value * self.DT)\n",
    "        \n",
    "        self.x_lead += self.v_lead * self.DT\n",
    "        \n",
    "        # Get new observation\n",
    "        obs = self._get_obs()\n",
    "        \n",
    "        # Check collision\n",
    "        collision = obs[0] <= 0.0\n",
    "        \n",
    "        # Compute reward\n",
    "        speed_error = self.v_ego - self.V_REF\n",
    "        d_safe = self.D0 + self.TH * self.v_ego\n",
    "        safe_violation = max(0.0, d_safe - obs[0])\n",
    "        \n",
    "        reward = -(\n",
    "            0.5 * speed_error ** 2 +\n",
    "            2.0 * safe_violation ** 2 +\n",
    "            0.01 * a_safe ** 2\n",
    "        )\n",
    "        \n",
    "        # Update step counter\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Check termination\n",
    "        terminated = collision\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "        \n",
    "        info = {\n",
    "            \"collision\": collision,\n",
    "            \"dx\": float(obs[0]),\n",
    "            \"ego_v\": float(obs[2]),\n",
    "            \"lead_v\": float(self.v_lead),\n",
    "            \"applied_action\": float(a_safe),\n",
    "            \"rl_action\": float(a_rl),\n",
    "        }\n",
    "        \n",
    "        return obs, float(reward), terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        dx = self.x_lead - self.x_ego\n",
    "        print(f\"Step {self.current_step:3d} | dx={dx:6.2f}m | \"\n",
    "              f\"v_ego={self.v_ego:5.2f}m/s | v_lead={self.v_lead:5.2f}m/s | \"\n",
    "              f\"a={self.a_ego:5.2f}m/s²\")\n",
    "    \n",
    "    def activate_lead_deceleration(self, start_time=5.0, duration=3.0, decel=-2.0):\n",
    "        self.lead_decel_active = True\n",
    "        self.lead_decel_start = start_time\n",
    "        self.lead_decel_duration = duration\n",
    "        self.lead_decel_value = decel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class AttackBase:\n",
    "    def __init__(self, model, epsilon=0.01):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.device = next(model.policy.parameters()).device\n",
    "    \n",
    "    def perturb(self, obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class FGSM(AttackBase):\n",
    "    def perturb(self, obs):\n",
    "        obs_np = np.array(obs, dtype=np.float32)\n",
    "        is_batched = len(obs_np.shape) == 2\n",
    "        \n",
    "        if not is_batched:\n",
    "            obs_np = obs_np.reshape(1, -1)\n",
    "        \n",
    "        # Convert to torch tensor\n",
    "        obs_tensor = torch.tensor(obs_np, dtype=torch.float32, device=self.device)\n",
    "        obs_tensor.requires_grad = True\n",
    "        \n",
    "        # Forward pass through policy to get mean action\n",
    "        with torch.enable_grad():\n",
    "            # Get policy features and mean action\n",
    "            features = self.model.policy.extract_features(obs_tensor)\n",
    "            latent_pi = self.model.policy.mlp_extractor.forward_actor(features)\n",
    "            mean_actions = self.model.policy.action_net(latent_pi)\n",
    "            loss = mean_actions.sum()\n",
    "            loss.backward()\n",
    "        \n",
    "        # Get gradient and compute perturbation\n",
    "        grad = obs_tensor.grad.cpu().numpy()\n",
    "        perturbation = self.epsilon * np.sign(grad)\n",
    "        \n",
    "        # Apply perturbation and clip to valid range [-1, 1]\n",
    "        obs_adv = obs_np + perturbation\n",
    "        obs_adv = np.clip(obs_adv, -1.0, 1.0)\n",
    "        \n",
    "        # Return in original shape\n",
    "        if not is_batched:\n",
    "            obs_adv = obs_adv.squeeze(0)\n",
    "        \n",
    "        return obs_adv\n",
    "\n",
    "\n",
    "class OIA(AttackBase):\n",
    "    def perturb(self, obs):\n",
    "        # Handle both single obs and batched obs\n",
    "        obs_np = np.array(obs, dtype=np.float32)\n",
    "        is_batched = len(obs_np.shape) == 2\n",
    "        \n",
    "        if not is_batched:\n",
    "            obs_np = obs_np.reshape(1, -1)\n",
    "        \n",
    "        # Convert to torch tensor\n",
    "        obs_tensor = torch.tensor(obs_np, dtype=torch.float32, device=self.device)\n",
    "        obs_tensor.requires_grad = True\n",
    "        \n",
    "        # Forward pass through value network\n",
    "        with torch.enable_grad():\n",
    "            # Get value estimate\n",
    "            features = self.model.policy.extract_features(obs_tensor)\n",
    "            latent_vf = self.model.policy.mlp_extractor.forward_critic(features)\n",
    "            value = self.model.policy.value_net(latent_vf)\n",
    "            \n",
    "            # Compute gradient of value w.r.t. observation\n",
    "            value.sum().backward()\n",
    "        \n",
    "        # Get gradient and compute perturbation\n",
    "        grad = obs_tensor.grad.cpu().numpy()\n",
    "        perturbation = self.epsilon * np.sign(grad)\n",
    "        \n",
    "        # Apply perturbation and clip to valid range [-1, 1]\n",
    "        obs_adv = obs_np + perturbation\n",
    "        obs_adv = np.clip(obs_adv, -1.0, 1.0)\n",
    "        \n",
    "        # Return in original shape\n",
    "        if not is_batched:\n",
    "            obs_adv = obs_adv.squeeze(0)\n",
    "        \n",
    "        return obs_adv\n",
    "\n",
    "\n",
    "def create_attack(attack_type, model, epsilon=0.01):\n",
    "    if attack_type.lower() == 'fgsm':\n",
    "        return FGSM(model, epsilon)\n",
    "    elif attack_type.lower() == 'oia':\n",
    "        return OIA(model, epsilon)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown attack type: {attack_type}\")\n",
    "\n",
    "\n",
    "class AttackWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, attack, apply_to_safety_filter=True):\n",
    "        super().__init__(env)\n",
    "        self.attack = attack\n",
    "        self.apply_to_safety_filter = apply_to_safety_filter\n",
    "        \n",
    "        # Track original and perturbed observations for RMSE computation\n",
    "        self.original_obs = None\n",
    "        self.perturbed_obs = None\n",
    "        self.step_rmse_values = []\n",
    "        self.episode_rmse = 0.0\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        \n",
    "        # Store original observation\n",
    "        self.original_obs = obs.copy()\n",
    "        \n",
    "        # Perturb observation\n",
    "        self.perturbed_obs = self.attack.perturb(obs)\n",
    "        \n",
    "        # Compute step RMSE\n",
    "        step_rmse = np.sqrt(np.mean((self.perturbed_obs - self.original_obs) ** 2))\n",
    "        self.step_rmse_values = [step_rmse]\n",
    "        self.episode_rmse = step_rmse\n",
    "        \n",
    "        # Apply to safety filter if enabled\n",
    "        if self.apply_to_safety_filter and hasattr(self.env, 'set_safety_obs_for_filter'):\n",
    "            self.env.set_safety_obs_for_filter(self.perturbed_obs)\n",
    "        \n",
    "        return self.perturbed_obs, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.original_obs = obs.copy()\n",
    "        self.perturbed_obs = self.attack.perturb(obs)\n",
    "        \n",
    "        # Compute step RMSE\n",
    "        step_rmse = np.sqrt(np.mean((self.perturbed_obs - self.original_obs) ** 2))\n",
    "        self.step_rmse_values.append(step_rmse)\n",
    "        \n",
    "        # Apply to safety filter if enabled\n",
    "        if self.apply_to_safety_filter and hasattr(self.env, 'set_safety_obs_for_filter'):\n",
    "            self.env.set_safety_obs_for_filter(self.perturbed_obs)\n",
    "        \n",
    "        # Add RMSE to info\n",
    "        info['step_rmse'] = step_rmse\n",
    "        info['episode_rmse_mean'] = np.mean(self.step_rmse_values)\n",
    "        \n",
    "        return self.perturbed_obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def get_episode_rmse(self):\n",
    "        return np.mean(self.step_rmse_values) if self.step_rmse_values else 0.0\n",
    "\n",
    "\n",
    "class FGSMAttackWrapper(AttackWrapper):\n",
    "    def __init__(self, env, model, epsilon=0.01):\n",
    "        attack = FGSM(model, epsilon)\n",
    "        super().__init__(env, attack, apply_to_safety_filter=True)\n",
    "\n",
    "\n",
    "class OIAAttackWrapper(AttackWrapper):\n",
    "    def __init__(self, env, model, epsilon=0.01):\n",
    "        attack = OIA(model, epsilon)\n",
    "        super().__init__(env, attack, apply_to_safety_filter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "# from acc_env import ACCEnv  # Already defined above\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    \"\"\"Create a single ACC environment instance\"\"\"\n",
    "    return ACCEnv()\n",
    "\n",
    "\n",
    "def train_ppo(\n",
    "    total_timesteps=200000,\n",
    "    n_envs=8,\n",
    "    save_dir=\"models\",\n",
    "    save_freq=50000\n",
    "):\n",
    "    \"\"\"\n",
    "    Train PPO agent with vectorized environments and observation normalization.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Creating vectorized environments...\")\n",
    "    # Create vectorized environment\n",
    "    vec_env = DummyVecEnv([make_env for _ in range(n_envs)])\n",
    "    vec_env = VecNormalize(\n",
    "        vec_env,\n",
    "        norm_obs=True,\n",
    "        norm_reward=False,\n",
    "        clip_obs=10.0,\n",
    "        gamma=0.99\n",
    "    )\n",
    "    \n",
    "    print(\"Creating PPO model...\")\n",
    "    # PPO hyperparameters (from assignment suggestion)\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=128,\n",
    "        batch_size=128,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.0,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./logs\"\n",
    "    )\n",
    "    \n",
    "    # Setup checkpoint callback\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=save_freq // n_envs,  # adjust for parallel envs\n",
    "        save_path=save_dir,\n",
    "        name_prefix=\"ppo_acc\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {total_timesteps} timesteps...\")\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=checkpoint_callback,\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # Save final model and normalization stats\n",
    "    model.save(os.path.join(save_dir, \"ppo_acc_final\"))\n",
    "    vec_env.save(os.path.join(save_dir, \"vec_normalize.pkl\"))\n",
    "    \n",
    "    print(f\"\\nTraining complete. Model saved to {save_dir}\")\n",
    "    print(f\"Observation mean: {vec_env.obs_rms.mean}\")\n",
    "    print(f\"Observation var: {vec_env.obs_rms.var}\")\n",
    "    \n",
    "    return model, vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with default settings\n",
    "model, vec_env = train_ppo(\n",
    "    total_timesteps=200000,\n",
    "    n_envs=8,\n",
    "    save_dir=\"models\",\n",
    "    save_freq=50000\n",
    ")\n",
    "print(\"\\nTraining finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "# from acc_env import ACCEnv  # Already defined above\n",
    "# from attacks import create_attack  # Already defined above\n",
    "\n",
    "\n",
    "def evaluate_single_condition(vec_env, base_env, model, attack, n_episodes, \n",
    "                              scenario_config, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate agent for one condition (baseline or attack).\n",
    "    \"\"\"\n",
    "    collisions = []\n",
    "    returns = []\n",
    "    min_dx_values = []\n",
    "    episodes_data = []\n",
    "    rmse_values = []  # Track RMSE for each episode\n",
    "    \n",
    "    for ep in range(n_episodes):\n",
    "        obs = vec_env.reset()\n",
    "        \n",
    "        # Configure scenario\n",
    "        if scenario_config.get('use_lead_decel', False):\n",
    "            base_env.activate_lead_deceleration(\n",
    "                start_time=scenario_config.get('decel_start', 5.0),\n",
    "                duration=scenario_config.get('decel_duration', 3.0),\n",
    "                decel=scenario_config.get('decel_value', -2.0)\n",
    "            )\n",
    "        \n",
    "        episode_return = 0.0\n",
    "        episode_collision = False\n",
    "        min_dx = float('inf')\n",
    "        episode_rmse_steps = []  # RMSE for each step in episode\n",
    "        \n",
    "        # Store trajectory for first 3 episodes\n",
    "        if ep < 3:\n",
    "            trajectory = {\n",
    "                't': [], 'dx': [], 'dv': [], 'v': [],\n",
    "                'rl_action': [], 'applied_action': [], 'lead_v': [],\n",
    "                'step_rmse': []  # Add RMSE tracking\n",
    "            }\n",
    "        else:\n",
    "            trajectory = None\n",
    "        \n",
    "        done = False\n",
    "        step = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Store original observation for RMSE calculation\n",
    "            obs_original = obs.copy()\n",
    "            obs_for_policy = obs.copy()\n",
    "            \n",
    "            # Apply attack if present\n",
    "            if attack is not None:\n",
    "                obs_adv = attack.perturb(obs[0])\n",
    "                base_env.set_safety_obs_for_filter(obs_adv)\n",
    "                obs_for_policy = obs_adv.reshape(1, -1)\n",
    "                \n",
    "                # Compute step RMSE (between original and perturbed observations)\n",
    "                step_rmse = np.sqrt(np.mean((obs_adv - obs[0]) ** 2))\n",
    "                episode_rmse_steps.append(step_rmse)\n",
    "            else:\n",
    "                step_rmse = 0.0  # No perturbation for baseline\n",
    "            \n",
    "            # Get action from policy\n",
    "            action, _ = model.predict(obs_for_policy, deterministic=True)\n",
    "            \n",
    "            # Step environment\n",
    "            obs, reward, terminated, info = vec_env.step(action)\n",
    "            \n",
    "            episode_return += reward[0]\n",
    "            min_dx = min(min_dx, info[0][\"dx\"])\n",
    "            \n",
    "            if info[0].get(\"collision\", False):\n",
    "                episode_collision = True\n",
    "            \n",
    "            # Record trajectory\n",
    "            if trajectory is not None:\n",
    "                trajectory['t'].append(step * ACCEnv.DT)\n",
    "                trajectory['dx'].append(info[0][\"dx\"])\n",
    "                trajectory['dv'].append(info[0][\"lead_v\"] - info[0][\"ego_v\"])\n",
    "                trajectory['v'].append(info[0][\"ego_v\"])\n",
    "                trajectory['rl_action'].append(info[0][\"rl_action\"])\n",
    "                trajectory['applied_action'].append(info[0][\"applied_action\"])\n",
    "                trajectory['lead_v'].append(info[0][\"lead_v\"])\n",
    "                trajectory['step_rmse'].append(step_rmse)\n",
    "            \n",
    "            done = terminated[0] or info[0].get(\"TimeLimit.truncated\", False)\n",
    "            step += 1\n",
    "        \n",
    "        collisions.append(episode_collision)\n",
    "        returns.append(episode_return)\n",
    "        min_dx_values.append(min_dx)\n",
    "        \n",
    "        # Compute episode mean RMSE\n",
    "        if episode_rmse_steps:\n",
    "            episode_mean_rmse = np.mean(episode_rmse_steps)\n",
    "        else:\n",
    "            episode_mean_rmse = 0.0\n",
    "        rmse_values.append(episode_mean_rmse)\n",
    "        \n",
    "        if trajectory is not None:\n",
    "            episodes_data.append(trajectory)\n",
    "        \n",
    "        if verbose and (ep + 1) % 20 == 0:\n",
    "            curr_coll = sum(collisions) / len(collisions)\n",
    "            curr_ret = np.mean(returns)\n",
    "            curr_rmse = np.mean(rmse_values)\n",
    "            print(f\"  Episode {ep+1}/{n_episodes}: \"\n",
    "                  f\"Collision={curr_coll:.3f}, Return={curr_ret:.2f}, RMSE={curr_rmse:.4f}\")\n",
    "    \n",
    "    # Compute jerk\n",
    "    jerks = []\n",
    "    for traj in episodes_data:\n",
    "        actions = np.array(traj[\"applied_action\"])\n",
    "        if len(actions) > 1:\n",
    "            jerk = np.mean(np.abs(np.diff(actions)))\n",
    "            jerks.append(jerk)\n",
    "    mean_jerk = float(np.mean(jerks)) if jerks else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"collision_rate\": float(sum(collisions) / n_episodes),\n",
    "        \"mean_return\": float(np.mean(returns)),\n",
    "        \"std_return\": float(np.std(returns)),\n",
    "        \"mean_jerk\": mean_jerk,\n",
    "        \"mean_rmse\": float(np.mean(rmse_values)),  # Add mean RMSE\n",
    "        \"std_rmse\": float(np.std(rmse_values)),    # Add std RMSE\n",
    "        \"min_dx_mean\": float(np.mean(min_dx_values)),\n",
    "        \"min_dx_std\": float(np.std(min_dx_values)),\n",
    "        \"episodes\": episodes_data\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation(\n",
    "    model_path=\"models/ppo_acc_final.zip\",\n",
    "    vec_normalize_path=\"models/vec_normalize.pkl\",\n",
    "    n_episodes=100,\n",
    "    epsilon=0.01,\n",
    "    scenario=\"normal\",\n",
    "    output_dir=\"results\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run complete evaluation with baseline, FGSM, and OIA.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Configure scenario\n",
    "    scenario_configs = {\n",
    "        'normal': {\n",
    "            'use_lead_decel': False,\n",
    "            'description': 'Normal driving (no lead braking)'\n",
    "        },\n",
    "        'challenging': {\n",
    "            'use_lead_decel': True,\n",
    "            'decel_value': -2.0,\n",
    "            'description': 'Challenging (lead brakes at -2.0 m/s²)'\n",
    "        },\n",
    "        'gentle': {\n",
    "            'use_lead_decel': True,\n",
    "            'decel_value': -1.5,\n",
    "            'description': 'Gentle challenge (lead brakes at -1.5 m/s²)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    scenario_config = scenario_configs.get(scenario, scenario_configs['normal'])\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"EVALUATION: {scenario_config['description']}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Episodes per condition: {n_episodes}\")\n",
    "    print(f\"Attack epsilon: {epsilon}\")\n",
    "    print()\n",
    "    \n",
    "    # Load model and environment\n",
    "    print(\"Loading model and environment...\")\n",
    "    vec_env = DummyVecEnv([lambda: ACCEnv()])\n",
    "    vec_env = VecNormalize.load(vec_normalize_path, vec_env)\n",
    "    vec_env.training = False\n",
    "    vec_env.norm_reward = False\n",
    "    \n",
    "    model = PPO.load(model_path, env=vec_env)\n",
    "    base_env = vec_env.envs[0]\n",
    "    \n",
    "    # Run evaluations\n",
    "    results = {}\n",
    "    \n",
    "    # Baseline\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"BASELINE\")\n",
    "    print(\"=\" * 70)\n",
    "    baseline_results = evaluate_single_condition(\n",
    "        vec_env, base_env, model, None, n_episodes, scenario_config\n",
    "    )\n",
    "    results['baseline'] = baseline_results\n",
    "    \n",
    "    # FGSM\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"FGSM ATTACK (ε={epsilon})\")\n",
    "    print(\"=\" * 70)\n",
    "    fgsm_attack = create_attack(\"fgsm\", model, epsilon)\n",
    "    fgsm_results = evaluate_single_condition(\n",
    "        vec_env, base_env, model, fgsm_attack, n_episodes, scenario_config\n",
    "    )\n",
    "    results['fgsm'] = fgsm_results\n",
    "    \n",
    "    # OIA\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"OIA ATTACK (ε={epsilon})\")\n",
    "    print(\"=\" * 70)\n",
    "    oia_attack = create_attack(\"oia\", model, epsilon)\n",
    "    oia_results = evaluate_single_condition(\n",
    "        vec_env, base_env, model, oia_attack, n_episodes, scenario_config\n",
    "    )\n",
    "    results['oia'] = oia_results\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nBaseline:\")\n",
    "    print(f\"  Collision Rate: {baseline_results['collision_rate']:.3f}\")\n",
    "    print(f\"  Mean Return: {baseline_results['mean_return']:.2f} ± {baseline_results['std_return']:.2f}\")\n",
    "    print(f\"  Mean Jerk: {baseline_results['mean_jerk']:.4f}\")\n",
    "    print(f\"  Mean RMSE: {baseline_results['mean_rmse']:.4f} (no attack)\")\n",
    "    \n",
    "    print(f\"\\nFGSM (ε={epsilon}):\")\n",
    "    print(f\"  Collision Rate: {fgsm_results['collision_rate']:.3f}\")\n",
    "    print(f\"  Mean Return: {fgsm_results['mean_return']:.2f} ± {fgsm_results['std_return']:.2f}\")\n",
    "    print(f\"  Mean Jerk: {fgsm_results['mean_jerk']:.4f}\")\n",
    "    print(f\"  Mean RMSE: {fgsm_results['mean_rmse']:.4f} (stealth)\")\n",
    "    \n",
    "    print(f\"\\nOIA (ε={epsilon}):\")\n",
    "    print(f\"  Collision Rate: {oia_results['collision_rate']:.3f}\")\n",
    "    print(f\"  Mean Return: {oia_results['mean_return']:.2f} ± {oia_results['std_return']:.2f}\")\n",
    "    print(f\"  Mean Jerk: {oia_results['mean_jerk']:.4f}\")\n",
    "    print(f\"  Mean RMSE: {oia_results['mean_rmse']:.4f} (stealth)\")\n",
    "    \n",
    "    # Compute degradation\n",
    "    fgsm_deg = baseline_results['mean_return'] - fgsm_results['mean_return']\n",
    "    oia_deg = baseline_results['mean_return'] - oia_results['mean_return']\n",
    "    \n",
    "    print(f\"\\nPerformance Degradation:\")\n",
    "    print(f\"  FGSM: {fgsm_deg:.2f}\")\n",
    "    print(f\"  OIA: {oia_deg:.2f}\")\n",
    "    if oia_deg > 0 and fgsm_deg > 0:\n",
    "        ratio = oia_deg / fgsm_deg\n",
    "        print(f\"  OIA is {ratio:.2f}x more damaging than FGSM\")\n",
    "    \n",
    "    if oia_results['collision_rate'] > fgsm_results['collision_rate']:\n",
    "        coll_ratio = oia_results['collision_rate'] / max(fgsm_results['collision_rate'], 0.01)\n",
    "        print(f\"  OIA causes {coll_ratio:.2f}x more collisions than FGSM\")\n",
    "    \n",
    "    # Stealth comparison\n",
    "    print(f\"\\nStealth (RMSE - Lower is Stealthier):\")\n",
    "    print(f\"  FGSM: {fgsm_results['mean_rmse']:.4f}\")\n",
    "    print(f\"  OIA: {oia_results['mean_rmse']:.4f}\")\n",
    "    if fgsm_results['mean_rmse'] > oia_results['mean_rmse']:\n",
    "        stealth_ratio = fgsm_results['mean_rmse'] / max(oia_results['mean_rmse'], 1e-6)\n",
    "        print(f\"  OIA is {stealth_ratio:.2f}x more stealthy than FGSM\")\n",
    "    elif oia_results['mean_rmse'] > fgsm_results['mean_rmse']:\n",
    "        stealth_ratio = oia_results['mean_rmse'] / max(fgsm_results['mean_rmse'], 1e-6)\n",
    "        print(f\"  FGSM is {stealth_ratio:.2f}x more stealthy than OIA\")\n",
    "    else:\n",
    "        print(f\"  Similar stealth levels\")\n",
    "    \n",
    "    # Save results\n",
    "    summary = {\n",
    "        'scenario': scenario,\n",
    "        'epsilon': float(epsilon),\n",
    "        'n_episodes': n_episodes,\n",
    "        'baseline': {\n",
    "            'collision_rate': baseline_results['collision_rate'],\n",
    "            'mean_return': baseline_results['mean_return'],\n",
    "            'std_return': baseline_results['std_return'],\n",
    "            'mean_jerk': baseline_results['mean_jerk'],\n",
    "            'mean_rmse': baseline_results['mean_rmse'],\n",
    "            'std_rmse': baseline_results['std_rmse'],\n",
    "        },\n",
    "        'fgsm': {\n",
    "            'collision_rate': fgsm_results['collision_rate'],\n",
    "            'mean_return': fgsm_results['mean_return'],\n",
    "            'std_return': fgsm_results['std_return'],\n",
    "            'mean_jerk': fgsm_results['mean_jerk'],\n",
    "            'mean_rmse': fgsm_results['mean_rmse'],\n",
    "            'std_rmse': fgsm_results['std_rmse'],\n",
    "            'epsilon': float(epsilon),\n",
    "        },\n",
    "        'oia': {\n",
    "            'collision_rate': oia_results['collision_rate'],\n",
    "            'mean_return': oia_results['mean_return'],\n",
    "            'std_return': oia_results['std_return'],\n",
    "            'mean_jerk': oia_results['mean_jerk'],\n",
    "            'mean_rmse': oia_results['mean_rmse'],\n",
    "            'std_rmse': oia_results['std_rmse'],\n",
    "            'epsilon': float(epsilon),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    summary_path = os.path.join(output_dir, 'summary.json')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nResults saved to {summary_path}\")\n",
    "    \n",
    "    # Save sample trajectories\n",
    "    for condition_name in ['baseline', 'fgsm', 'oia']:\n",
    "        condition_data = results[condition_name]\n",
    "        for i, ep_data in enumerate(condition_data['episodes']):\n",
    "            traj_path = os.path.join(output_dir, f'trajectory_{condition_name}_ep{i}.npz')\n",
    "            np.savez(traj_path, **ep_data)\n",
    "    \n",
    "    print(f\"Sample trajectories saved to {output_dir}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def run_multi_epsilon_evaluation(\n",
    "    model_path=\"models/ppo_acc_final.zip\",\n",
    "    vec_normalize_path=\"models/vec_normalize.pkl\",\n",
    "    n_episodes=100,\n",
    "    epsilons=[0.005, 0.01, 0.015, 0.02],\n",
    "    scenario=\"challenging\",\n",
    "    output_dir=\"results_multi_epsilon\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run evaluation across multiple epsilon values.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"TESTING EPSILON = {eps}\")\n",
    "        print('=' * 70)\n",
    "        \n",
    "        result = run_evaluation(\n",
    "            model_path=model_path,\n",
    "            vec_normalize_path=vec_normalize_path,\n",
    "            n_episodes=n_episodes,\n",
    "            epsilon=eps,\n",
    "            scenario=scenario,\n",
    "            output_dir=os.path.join(output_dir, f\"eps_{eps}\")\n",
    "        )\n",
    "        \n",
    "        all_results[f\"eps_{eps}\"] = result\n",
    "    \n",
    "    # Save combined results\n",
    "    combined_path = os.path.join(output_dir, 'multi_epsilon_summary.json')\n",
    "    with open(combined_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"MULTI-EPSILON SUMMARY\")\n",
    "    print('=' * 70)\n",
    "    \n",
    "    for eps_key, result in all_results.items():\n",
    "        eps_val = float(eps_key.split('_')[1])\n",
    "        print(f\"\\nε = {eps_val}:\")\n",
    "        print(f\"  Baseline:  Coll={result['baseline']['collision_rate']:.1%}, \"\n",
    "              f\"Return={result['baseline']['mean_return']:.1f}\")\n",
    "        print(f\"  FGSM:      Coll={result['fgsm']['collision_rate']:.1%}, \"\n",
    "              f\"Return={result['fgsm']['mean_return']:.1f}\")\n",
    "        print(f\"  OIA:       Coll={result['oia']['collision_rate']:.1%}, \"\n",
    "              f\"Return={result['oia']['mean_return']:.1f}\")\n",
    "    \n",
    "    print(f\"\\nCombined results saved to {combined_path}\")\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single evaluation run\n",
    "summary = run_evaluation(\n",
    "    model_path=\"models/ppo_acc_final.zip\",\n",
    "    vec_normalize_path=\"models/vec_normalize.pkl\",\n",
    "    n_episodes=100,\n",
    "    epsilon=0.01,\n",
    "    scenario=\"normal\",  # Options: 'normal', 'challenging', 'gentle'\n",
    "    output_dir=\"results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-epsilon evaluation\n",
    "all_results = run_multi_epsilon_evaluation(\n",
    "    model_path=\"models/ppo_acc_final.zip\",\n",
    "    vec_normalize_path=\"models/vec_normalize.pkl\",\n",
    "    n_episodes=100,\n",
    "    epsilons=[0.005, 0.01, 0.015, 0.02],\n",
    "    scenario=\"challenging\",\n",
    "    output_dir=\"results_multi_epsilon\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def analyze_results(summary_path=\"results/summary.json\"):\n",
    "    \"\"\"\n",
    "    Analyze and interpret evaluation results.\n",
    "    \"\"\"\n",
    "    with open(summary_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"EVALUATION RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    baseline = summary[\"baseline\"]\n",
    "    fgsm = summary[\"fgsm\"]\n",
    "    oia = summary[\"oia\"]\n",
    "    \n",
    "    print(\"\\n1. COLLISION RATE ANALYSIS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"   Baseline:  {baseline['collision_rate']:.1%}\")\n",
    "    print(f\"   FGSM:      {fgsm['collision_rate']:.1%}  \"\n",
    "          f\"(+{(fgsm['collision_rate'] - baseline['collision_rate'])*100:.1f} pp)\")\n",
    "    print(f\"   OIA:       {oia['collision_rate']:.1%}  \"\n",
    "          f\"(+{(oia['collision_rate'] - baseline['collision_rate'])*100:.1f} pp)\")\n",
    "    \n",
    "    if oia['collision_rate'] > fgsm['collision_rate']:\n",
    "        print(f\"OIA causes {oia['collision_rate']/max(fgsm['collision_rate'], 1e-6):.1f}x more collisions than FGSM\")\n",
    "    elif oia['collision_rate'] == fgsm['collision_rate'] == baseline['collision_rate'] == 0:\n",
    "        print(f\"No collisions in any condition - safety filter too strong or scenarios too easy\")\n",
    "    \n",
    "    print(\"\\n2. EPISODE RETURN ANALYSIS (Higher is Better)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"   Baseline:  {baseline['mean_return']:7.2f} ± {baseline['std_return']:.2f}\")\n",
    "    print(f\"   FGSM:      {fgsm['mean_return']:7.2f} ± {fgsm['std_return']:.2f}  \"\n",
    "          f\"({fgsm['mean_return'] - baseline['mean_return']:+.2f})\")\n",
    "    print(f\"   OIA:       {oia['mean_return']:7.2f} ± {oia['std_return']:.2f}  \"\n",
    "          f\"({oia['mean_return'] - baseline['mean_return']:+.2f})\")\n",
    "    \n",
    "    baseline_degradation = baseline['mean_return'] - baseline['mean_return']\n",
    "    fgsm_degradation = baseline['mean_return'] - fgsm['mean_return']\n",
    "    oia_degradation = baseline['mean_return'] - oia['mean_return']\n",
    "    \n",
    "    print(f\"\\n   Performance Degradation:\")\n",
    "    print(f\"   - FGSM: {fgsm_degradation:.2f} ({(fgsm_degradation/abs(baseline['mean_return']))*100:.1f}%)\")\n",
    "    print(f\"   - OIA:  {oia_degradation:.2f} ({(oia_degradation/abs(baseline['mean_return']))*100:.1f}%)\")\n",
    "    \n",
    "    if oia_degradation > fgsm_degradation:\n",
    "        ratio = oia_degradation / max(fgsm_degradation, 1e-6)\n",
    "        print(f\"OIA degrades performance {ratio:.1f}x more than FGSM\")\n",
    "    else:\n",
    "        print(f\"OIA should degrade performance more than FGSM\")\n",
    "    \n",
    "    print(\"\\n3. JERK ANALYSIS (Lower is Smoother)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"   Baseline:  {baseline['mean_jerk']:.4f} m/s³\")\n",
    "    print(f\"   FGSM:      {fgsm['mean_jerk']:.4f} m/s³  \"\n",
    "          f\"({fgsm['mean_jerk'] - baseline['mean_jerk']:+.4f})\")\n",
    "    print(f\"   OIA:       {oia['mean_jerk']:.4f} m/s³  \"\n",
    "          f\"({oia['mean_jerk'] - baseline['mean_jerk']:+.4f})\")\n",
    "    \n",
    "    if fgsm['mean_jerk'] > baseline['mean_jerk'] or oia['mean_jerk'] > baseline['mean_jerk']:\n",
    "        print(f\"Attacks cause less smooth control (higher jerk)\")\n",
    "    \n",
    "    print(\"\\n4. STEALTH ANALYSIS (RMSE - Lower is Stealthier)\")\n",
    "    print(\"-\" * 70)\n",
    "    baseline_rmse = baseline.get('mean_rmse', 0.0)\n",
    "    fgsm_rmse = fgsm.get('mean_rmse', 0.0)\n",
    "    oia_rmse = oia.get('mean_rmse', 0.0)\n",
    "    \n",
    "    print(f\"   Baseline:  {baseline_rmse:.4f} (no perturbation)\")\n",
    "    print(f\"   FGSM:      {fgsm_rmse:.4f}\")\n",
    "    print(f\"   OIA:       {oia_rmse:.4f}\")\n",
    "    \n",
    "    if fgsm_rmse > 0 and oia_rmse > 0:\n",
    "        if oia_rmse < fgsm_rmse:\n",
    "            stealth_ratio = fgsm_rmse / oia_rmse\n",
    "            print(f\"OIA is {stealth_ratio:.2f}x more stealthy than FGSM\")\n",
    "            print(f\"     (Lower RMSE means smaller perturbations)\")\n",
    "        elif fgsm_rmse < oia_rmse:\n",
    "            stealth_ratio = oia_rmse / fgsm_rmse\n",
    "            print(f\"FGSM is {stealth_ratio:.2f}x more stealthy than OIA\")\n",
    "            print(f\"     (Lower RMSE means smaller perturbations)\")\n",
    "        else:\n",
    "            print(f\"   ≈ Similar stealth levels\")\n",
    "    \n",
    "    print(\"\\n5. KEY FINDINGS\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    findings = []\n",
    "    \n",
    "    # Check if OIA is more effective\n",
    "    if oia_degradation > fgsm_degradation * 1.2:\n",
    "        findings.append(\"OIA is significantly more effective than FGSM at degrading performance\")\n",
    "    elif oia_degradation > fgsm_degradation:\n",
    "        findings.append(\"OIA is more effective than FGSM (as expected)\")\n",
    "    else:\n",
    "        findings.append(\"OIA should be more effective than FGSM - consider increasing epsilon or using lead deceleration\")\n",
    "    \n",
    "    # Check collision rates\n",
    "    if baseline['collision_rate'] == 0 and oia['collision_rate'] == 0:\n",
    "        findings.append(\"No collisions observed - safety filter is working but scenarios may be too easy\")\n",
    "        findings.append(\"  Recommendation: Enable lead vehicle deceleration with use_lead_decel=True\")\n",
    "    elif oia['collision_rate'] > 0:\n",
    "        findings.append(f\"OIA successfully causes collisions ({oia['collision_rate']:.1%} rate)\")\n",
    "    \n",
    "    # Check stealth\n",
    "    fgsm_rmse = fgsm.get('mean_rmse', 0.0)\n",
    "    oia_rmse = oia.get('mean_rmse', 0.0)\n",
    "    if fgsm_rmse > 0 and oia_rmse > 0:\n",
    "        if oia_rmse < fgsm_rmse:\n",
    "            findings.append(f\"OIA is more stealthy than FGSM (RMSE: {oia_rmse:.4f} vs {fgsm_rmse:.4f})\")\n",
    "            findings.append(\"  → OIA is BOTH more effective AND more stealthy!\")\n",
    "        elif fgsm_rmse < oia_rmse:\n",
    "            findings.append(f\"FGSM is more stealthy than OIA (RMSE: {fgsm_rmse:.4f} vs {oia_rmse:.4f})\")\n",
    "            findings.append(\"  → OIA is more effective but less stealthy\")\n",
    "        else:\n",
    "            findings.append(f\"≈ Similar stealth levels (RMSE: {oia_rmse:.4f})\")\n",
    "    \n",
    "    # Check return degradation magnitude\n",
    "    if abs(oia_degradation) > 10:\n",
    "        findings.append(f\"OIA causes substantial performance degradation ({oia_degradation:.1f} return decrease)\")\n",
    "    \n",
    "    # Check jerk increase\n",
    "    if oia['mean_jerk'] > baseline['mean_jerk'] * 2:\n",
    "        findings.append(\"OIA causes significantly less smooth control behavior\")\n",
    "    \n",
    "    for finding in findings:\n",
    "        print(f\"   {finding}\")\n",
    "    \n",
    "    print(\"\\n6. INTERPRETATION\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"\"\"\n",
    "   The results show that both FGSM and OIA adversarial attacks successfully\n",
    "   degrade the PPO agent's performance compared to baseline:\n",
    "   \n",
    "   - FGSM perturbs observations to change the policy's immediate action output\n",
    "   - OIA perturbs observations to inflate the value estimate, making the agent\n",
    "     overly optimistic about safety\n",
    "   \n",
    "   Key difference: OIA's optimism causes DELAYED reactions to threats because\n",
    "   the agent believes it's safer than it actually is. This makes OIA more\n",
    "   dangerous in safety-critical scenarios.\n",
    "   \n",
    "   The safety filter (CBF) prevents many collisions, but attacks can still\n",
    "   manipulate it by feeding adversarial observations. When the filter receives\n",
    "   false safety information, it may allow unsafe actions.\n",
    "   \"\"\")\n",
    "    \n",
    "    if baseline['collision_rate'] == 0:\n",
    "        print(\"\"\"\n",
    "   NOTE: Zero collisions suggest the safety filter is very effective in the\n",
    "   default scenarios. To see more dramatic effects:\n",
    "   \n",
    "   1. Enable lead vehicle deceleration: use_lead_decel=True\n",
    "   2. Increase attack strength: epsilon=0.02 or 0.03\n",
    "   3. Use more challenging initial conditions\n",
    "   \"\"\")\n",
    "    \n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis (Optional)\n",
    "\n",
    "Uncomment and run after evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "results_path = \"results/summary.json\"\n",
    "if not os.path.exists(results_path):\n",
    "    print(f\"Error: {results_path} not found. Run evaluate.py first.\")\n",
    "else:\n",
    "    analyze_results(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_single_trajectory(traj_path, save_path=None):\n",
    "    data = np.load(traj_path)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "    \n",
    "    # Plot 1: Distance headway\n",
    "    axes[0].plot(data[\"t\"], data[\"dx\"], 'b-', linewidth=1.5, label=\"Distance headway\")\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', linewidth=1, label=\"Collision threshold\")\n",
    "    axes[0].set_ylabel(\"dx (m)\", fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(fontsize=9)\n",
    "    axes[0].set_title(\"Trajectory Analysis\", fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Velocities\n",
    "    axes[1].plot(data[\"t\"], data[\"v\"], 'b-', linewidth=1.5, label=\"Ego velocity\")\n",
    "    axes[1].plot(data[\"t\"], data[\"lead_v\"], 'g--', linewidth=1.5, label=\"Lead velocity\")\n",
    "    axes[1].set_ylabel(\"Velocity (m/s)\", fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend(fontsize=9)\n",
    "    \n",
    "    # Plot 3: Actions\n",
    "    axes[2].plot(data[\"t\"], data[\"rl_action\"], 'orange', linewidth=1, alpha=0.7, label=\"RL action\")\n",
    "    axes[2].plot(data[\"t\"], data[\"applied_action\"], 'b-', linewidth=1.5, label=\"Applied action (after safety filter)\")\n",
    "    axes[2].axhline(y=0, color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "    axes[2].set_ylabel(\"Acceleration (m/s²)\", fontsize=11)\n",
    "    axes[2].set_xlabel(\"Time (s)\", fontsize=11)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend(fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved figure to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_comparison(results_dir=\"results\", output_path=\"results/comparison.png\"):\n",
    "    # Load first episode from each condition\n",
    "    conditions = [\"baseline\", \"fgsm\", \"oia\"]\n",
    "    colors = {\"baseline\": \"blue\", \"fgsm\": \"orange\", \"oia\": \"red\"}\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    for condition in conditions:\n",
    "        traj_path = os.path.join(results_dir, f\"trajectory_{condition}_ep0.npz\")\n",
    "        \n",
    "        if not os.path.exists(traj_path):\n",
    "            print(f\"Warning: {traj_path} not found\")\n",
    "            continue\n",
    "        \n",
    "        data = np.load(traj_path)\n",
    "        color = colors[condition]\n",
    "        label = condition.upper()\n",
    "        \n",
    "        # Plot distance headway\n",
    "        axes[0].plot(data[\"t\"], data[\"dx\"], color=color, linewidth=1.5, \n",
    "                    label=label, alpha=0.8)\n",
    "        \n",
    "        # Plot ego velocity\n",
    "        axes[1].plot(data[\"t\"], data[\"v\"], color=color, linewidth=1.5, \n",
    "                    label=label, alpha=0.8)\n",
    "        \n",
    "        # Plot applied action\n",
    "        axes[2].plot(data[\"t\"], data[\"applied_action\"], color=color, \n",
    "                    linewidth=1.5, label=label, alpha=0.8)\n",
    "    \n",
    "    # Format plots\n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    axes[0].set_ylabel(\"Distance Headway (m)\", fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(fontsize=10, loc='best')\n",
    "    axes[0].set_title(\"Comparison: Baseline vs FGSM vs OIA\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    axes[1].set_ylabel(\"Ego Velocity (m/s)\", fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend(fontsize=10, loc='best')\n",
    "    \n",
    "    axes[2].axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    axes[2].set_ylabel(\"Applied Acceleration (m/s²)\", fontsize=12)\n",
    "    axes[2].set_xlabel(\"Time (s)\", fontsize=12)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend(fontsize=10, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved comparison figure to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_summary_metrics(summary_path=\"results/summary.json\", output_path=\"results/metrics.png\"):\n",
    "    import json\n",
    "    \n",
    "    with open(summary_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    conditions = [\"baseline\", \"fgsm\", \"oia\"]\n",
    "    collision_rates = [summary[c][\"collision_rate\"] for c in conditions]\n",
    "    mean_returns = [summary[c][\"mean_return\"] for c in conditions]\n",
    "    std_returns = [summary[c][\"std_return\"] for c in conditions]\n",
    "    jerks = [summary[c][\"mean_jerk\"] for c in conditions]\n",
    "    rmse_values = [summary[c].get(\"mean_rmse\", 0.0) for c in conditions]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Collision rate\n",
    "    axes[0, 0].bar(conditions, collision_rates, color=['blue', 'orange', 'red'], alpha=0.7)\n",
    "    axes[0, 0].set_ylabel(\"Collision Rate\", fontsize=12)\n",
    "    axes[0, 0].set_title(\"Collision Rate by Condition\", fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylim([0, max(collision_rates) * 1.2 if max(collision_rates) > 0 else 1.0])\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Mean return\n",
    "    axes[0, 1].bar(conditions, mean_returns, yerr=std_returns, \n",
    "               color=['blue', 'orange', 'red'], alpha=0.7, capsize=5)\n",
    "    axes[0, 1].set_ylabel(\"Episode Return\", fontsize=12)\n",
    "    axes[0, 1].set_title(\"Mean Episode Return\", fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Jerk\n",
    "    axes[1, 0].bar(conditions, jerks, color=['blue', 'orange', 'red'], alpha=0.7)\n",
    "    axes[1, 0].set_ylabel(\"Mean Jerk (m/s³)\", fontsize=12)\n",
    "    axes[1, 0].set_title(\"Mean Jerk (Control Smoothness)\", fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # RMSE (Stealth) - Lower is more stealthy\n",
    "    axes[1, 1].bar(conditions, rmse_values, color=['blue', 'orange', 'red'], alpha=0.7)\n",
    "    axes[1, 1].set_ylabel(\"Mean RMSE (Lower = Stealthier)\", fontsize=12)\n",
    "    axes[1, 1].set_title(\"Attack Stealth (RMSE)\", fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add values on top of bars for RMSE\n",
    "    for i, v in enumerate(rmse_values):\n",
    "        if v > 0:\n",
    "            axes[1, 1].text(i, v + max(rmse_values) * 0.02, f'{v:.4f}', \n",
    "                           ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved metrics figure to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_stealth_comparison(summary_path=\"results/summary.json\", output_path=\"results/stealth_comparison.png\"):\n",
    "    import json\n",
    "    \n",
    "    with open(summary_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    # Extract RMSE values (excluding baseline which should be 0)\n",
    "    fgsm_rmse = summary['fgsm'].get('mean_rmse', 0.0)\n",
    "    oia_rmse = summary['oia'].get('mean_rmse', 0.0)\n",
    "    fgsm_std = summary['fgsm'].get('std_rmse', 0.0)\n",
    "    oia_std = summary['oia'].get('std_rmse', 0.0)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    \n",
    "    attacks = ['FGSM', 'OIA']\n",
    "    rmse_means = [fgsm_rmse, oia_rmse]\n",
    "    rmse_stds = [fgsm_std, oia_std]\n",
    "    colors = ['orange', 'red']\n",
    "    \n",
    "    bars = ax.bar(attacks, rmse_means, yerr=rmse_stds, \n",
    "                  color=colors, alpha=0.7, capsize=10, width=0.6)\n",
    "    \n",
    "    ax.set_ylabel(\"RMSE (Root Mean Square Error)\", fontsize=14)\n",
    "    ax.set_title(\"Attack Stealth Comparison\\n(Lower RMSE = More Stealthy)\", \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (v, std) in enumerate(zip(rmse_means, rmse_stds)):\n",
    "        if v > 0:\n",
    "            ax.text(i, v + std + max(rmse_means) * 0.02, \n",
    "                   f'{v:.4f}\\n±{std:.4f}', \n",
    "                   ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add interpretation text\n",
    "    if oia_rmse < fgsm_rmse and oia_rmse > 0:\n",
    "        winner = \"OIA\"\n",
    "        ratio = fgsm_rmse / oia_rmse\n",
    "        textstr = f'{winner} is {ratio:.2f}x more stealthy\\n(Lower perturbation magnitude)'\n",
    "    elif fgsm_rmse < oia_rmse and fgsm_rmse > 0:\n",
    "        winner = \"FGSM\"\n",
    "        ratio = oia_rmse / fgsm_rmse\n",
    "        textstr = f'{winner} is {ratio:.2f}x more stealthy\\n(Lower perturbation magnitude)'\n",
    "    else:\n",
    "        textstr = 'Similar stealth levels'\n",
    "    \n",
    "    ax.text(0.5, 0.95, textstr, transform=ax.transAxes,\n",
    "           fontsize=11, verticalalignment='top', horizontalalignment='center',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved stealth comparison to {output_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate All Visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "results_dir = \"results\"\n",
    "\n",
    "# Generate all plots\n",
    "print(\"Generating visualization plots...\")\n",
    "\n",
    "# Individual trajectories\n",
    "for condition in [\"baseline\", \"fgsm\", \"oia\"]:\n",
    "    traj_path = os.path.join(results_dir, f\"trajectory_{condition}_ep0.npz\")\n",
    "    if os.path.exists(traj_path):\n",
    "        save_path = os.path.join(results_dir, f\"plot_{condition}.png\")\n",
    "        plot_single_trajectory(traj_path, save_path)\n",
    "\n",
    "# Comparison plot\n",
    "plot_comparison(results_dir, os.path.join(results_dir, \"comparison.png\"))\n",
    "\n",
    "# Summary metrics (now includes RMSE)\n",
    "summary_path = os.path.join(results_dir, \"summary.json\")\n",
    "if os.path.exists(summary_path):\n",
    "    plot_summary_metrics(summary_path, os.path.join(results_dir, \"metrics.png\"))\n",
    "    plot_stealth_comparison(summary_path, os.path.join(results_dir, \"stealth_comparison.png\"))\n",
    "\n",
    "print(\"\\nAll plots generated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
