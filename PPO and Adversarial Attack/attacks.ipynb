{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1b5316-3541-487d-8f7c-cf0616457865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported ACCEnv from acc_env.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 23:03:21.618009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files not found; doing a quick in-memory train so the demo can run...\n",
      "Quick train done; model/env are ready.\n",
      "\n",
      "✅ model and env are ready in this kernel.\n"
     ]
    }
   ],
   "source": [
    "# === Make model/env ready for the demo ===\n",
    "import os, sys, subprocess, shlex\n",
    "from IPython import get_ipython\n",
    "\n",
    "# 1) Ensure ACCEnv is defined (import .py; else convert .ipynb -> .py; else %run notebook)\n",
    "try:\n",
    "    from acc_env import ACCEnv  # if you already have acc_env.py alongside this notebook\n",
    "    print(\"Imported ACCEnv from acc_env.py\")\n",
    "except ModuleNotFoundError:\n",
    "    if os.path.exists(\"acc_env.ipynb\"):\n",
    "        print(\"Converting acc_env.ipynb -> acc_env.py ...\")\n",
    "        subprocess.run(shlex.split(\"jupyter nbconvert --to python acc_env.ipynb\"), check=True)\n",
    "        if os.getcwd() not in sys.path:\n",
    "            sys.path.append(os.getcwd())\n",
    "        from acc_env import ACCEnv\n",
    "        print(\"Imported ACCEnv from converted acc_env.py\")\n",
    "    else:\n",
    "        print(\"Running acc_env.ipynb directly...\")\n",
    "        get_ipython().run_line_magic(\"run\", \"./acc_env.ipynb\")\n",
    "        # ACCEnv should now be in globals\n",
    "\n",
    "# 2) Try to load saved PPO + VecNormalize; otherwise quick-train a small model\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "LOGDIR = \"runs/ppo_baseline\"  # change if you saved elsewhere\n",
    "vec_path = os.path.join(LOGDIR, \"vecnormalize.pkl\")\n",
    "mdl_path = os.path.join(LOGDIR, \"ppo_acc.zip\")\n",
    "\n",
    "def make_env(seed=123, brake_profile=True, normalize_obs=True):\n",
    "    def _thunk():\n",
    "        return ACCEnv(brake_profile=brake_profile, normalize_obs=normalize_obs, seed=seed)\n",
    "    return _thunk\n",
    "\n",
    "model = None\n",
    "env = None\n",
    "\n",
    "if os.path.exists(vec_path) and os.path.exists(mdl_path):\n",
    "    print(f\"Loading saved model/env from {LOGDIR} ...\")\n",
    "    base_env = DummyVecEnv([make_env(seed=123, brake_profile=True, normalize_obs=True)])\n",
    "    env = VecNormalize.load(vec_path, base_env)\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "    model = PPO.load(mdl_path, env=env)\n",
    "    print(\"Loaded saved PPO and VecNormalize.\")\n",
    "else:\n",
    "    print(\"Saved files not found; doing a quick in-memory train so the demo can run...\")\n",
    "    # quick train on a stationary-lead scenario (no braking) so it learns *something*\n",
    "    train_env = DummyVecEnv([make_env(seed=42, brake_profile=False, normalize_obs=True)])\n",
    "    train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=1.0)\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", train_env, seed=42, verbose=0,\n",
    "        n_steps=512, batch_size=128, learning_rate=3e-4,\n",
    "        gamma=0.99, gae_lambda=0.95, clip_range=0.2, ent_coef=0.0\n",
    "    )\n",
    "    model.learn(total_timesteps=8_000)  # small, fast\n",
    "    # build an eval env (with braking enabled) sharing the same VecNormalize statistics\n",
    "    eval_base = DummyVecEnv([make_env(seed=123, brake_profile=True, normalize_obs=True)])\n",
    "    env = VecNormalize(eval_base, norm_obs=True, norm_reward=False, clip_obs=1.0)\n",
    "    # copy normalization stats from training env so obs scales match what policy expects\n",
    "    env.obs_rms = train_env.obs_rms\n",
    "    env.ret_rms = train_env.ret_rms\n",
    "    env.training = False\n",
    "    print(\"Quick train done; model/env are ready.\")\n",
    "\n",
    "print(\"\\n✅ model and env are ready in this kernel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5b8f33-cef9-4c18-9de7-40c62c27542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6062c61-99c7-4ade-8468-b6bc37005906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_tensor(x: np.ndarray) -> torch.Tensor:\n",
    "    return torch.as_tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f86d3cb-5223-438b-9676-75fd66bd08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackWrapper:\n",
    "    \"\"\"Base wrapper that perturbs observations before the agent acts.\"\"\"\n",
    "    def __init__(self, model: Any, epsilon: float = 0.01, device: str = \"cpu\") -> None:\n",
    "        self.model = model\n",
    "        self.eps = float(epsilon)\n",
    "        self.device = device\n",
    "\n",
    "    def perturb(self, obs: np.ndarray) -> np.ndarray:\n",
    "        return obs\n",
    "\n",
    "    def act(self, obs: np.ndarray):\n",
    "        # Compute adversarial observation (gradients enabled in perturb),\n",
    "        # then call model.predict without gradients.\n",
    "        obs_adv = self.perturb(obs)\n",
    "        with torch.no_grad():\n",
    "            action, _ = self.model.predict(obs_adv, deterministic=True)\n",
    "        return action, obs_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498d2f36-1497-45c5-a59a-89b458f7cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSMAttack(AttackWrapper):\n",
    "    \"\"\"FGSM with respect to policy mean action (pre-squash).\"\"\"\n",
    "    def perturb(self, obs: np.ndarray) -> np.ndarray:\n",
    "        # prepare policy for gradients\n",
    "        self.model.policy.set_training_mode(True)\n",
    "        self.model.policy.zero_grad(set_to_none=True)\n",
    "\n",
    "        obs_t = _to_tensor(obs)\n",
    "        single = False\n",
    "        if obs_t.ndim == 1:\n",
    "            obs_t = obs_t.unsqueeze(0)\n",
    "            single = True\n",
    "        obs_t = obs_t.to(self.device)\n",
    "        obs_t.requires_grad_(True)\n",
    "\n",
    "        # forward through policy internals to get mean action\n",
    "        features = self.model.policy.extract_features(obs_t)\n",
    "        latent_pi, _ = self.model.policy.mlp_extractor(features)\n",
    "        mean_actions = self.model.policy.action_net(latent_pi)  # [B, act_dim]\n",
    "\n",
    "        # simple scalar objective: increase squared mean action\n",
    "        obj = (mean_actions ** 2).sum()\n",
    "        obj.backward()\n",
    "\n",
    "        grad_sign = torch.sign(obs_t.grad)\n",
    "        adv = torch.clamp(obs_t + self.eps * grad_sign, -1.0, 1.0)\n",
    "        adv_np = adv.detach().cpu().numpy()\n",
    "        return adv_np[0] if single else adv_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dcab2b-56d1-4114-8c78-b23132490b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OIAttack(AttackWrapper):\n",
    "    \"\"\"Optimism Induction Attack: increase the critic value V(s).\"\"\"\n",
    "    def perturb(self, obs: np.ndarray) -> np.ndarray:\n",
    "        self.model.policy.set_training_mode(True)\n",
    "        self.model.policy.zero_grad(set_to_none=True)\n",
    "\n",
    "        obs_t = _to_tensor(obs)\n",
    "        single = False\n",
    "        if obs_t.ndim == 1:\n",
    "            obs_t = obs_t.unsqueeze(0)\n",
    "            single = True\n",
    "        obs_t = obs_t.to(self.device)\n",
    "        obs_t.requires_grad_(True)\n",
    "\n",
    "        features = self.model.policy.extract_features(obs_t)\n",
    "        _, latent_vf = self.model.policy.mlp_extractor(features)\n",
    "        values = self.model.policy.value_net(latent_vf)  # [B,1]\n",
    "\n",
    "        obj = values.sum()\n",
    "        obj.backward()\n",
    "\n",
    "        grad_sign = torch.sign(obs_t.grad)\n",
    "        adv = torch.clamp(obs_t + self.eps * grad_sign, -1.0, 1.0)\n",
    "        adv_np = adv.detach().cpu().numpy()\n",
    "        return adv_np[0] if single else adv_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5873b849-fdd5-4797-a289-102a76645aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attack_sanity(model, env, eps=0.01):\n",
    "    atk = FGSMAttack(model, epsilon=eps, device=\"cpu\")\n",
    "    obs = env.reset()[0]\n",
    "    adv = atk.perturb(obs)\n",
    "    print(\"FGSM sanity:\")\n",
    "    print(\" original obs:\", obs)\n",
    "    print(\" adv obs     :\", adv)\n",
    "    print(\" max |Δ|     :\", float(np.max(np.abs(np.array(adv) - np.array(obs)))))\n",
    "\n",
    "    atk2 = OIAttack(model, epsilon=eps, device=\"cpu\")\n",
    "    adv2 = atk2.perturb(obs)\n",
    "    print(\"\\nOIA sanity:\")\n",
    "    print(\" original obs:\", obs)\n",
    "    print(\" adv obs     :\", adv2)\n",
    "    print(\" max |Δ|     :\", float(np.max(np.abs(np.array(adv2) - np.array(obs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fc024d-c2c0-4c5a-983e-28446173c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a one-step demo with current model/env (if available)...\n",
      "\n",
      "FGSM max |Δ|: 0.009999990463256836\n",
      "OIA  max |Δ|: 0.009999990463256836\n"
     ]
    }
   ],
   "source": [
    "# Quick demo run (will only work if `model` and `env` exist in the kernel).\n",
    "# If not present, this prints an instructive message.\n",
    "try:\n",
    "    print(\"Running a one-step demo with current model/env (if available)...\\n\")\n",
    "    atk = FGSMAttack(model, epsilon=0.01, device=\"cpu\")\n",
    "    obs = env.reset()[0]\n",
    "    adv = atk.perturb(obs)\n",
    "    print(\"FGSM max |Δ|:\", float(np.max(np.abs(np.array(adv) - np.array(obs)))))\n",
    "    atk2 = OIAttack(model, epsilon=0.01, device=\"cpu\")\n",
    "    adv2 = atk2.perturb(obs)\n",
    "    print(\"OIA  max |Δ|:\", float(np.max(np.abs(np.array(adv2) - np.array(obs)))))\n",
    "except NameError:\n",
    "    print(\"Define `model` and `env` (load your PPO and VecNormalize env) before running the demo cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
