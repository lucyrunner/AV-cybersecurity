{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a6fbdee-89cd-4e5f-8502-38b798348764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "\n",
    "def ensure_py(stem: str):\n",
    "    ipynb, py = f\"{stem}.ipynb\", f\"{stem}.py\"\n",
    "    if not os.path.exists(py) and os.path.exists(ipynb):\n",
    "        subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"python\", ipynb], check=True)\n",
    "        with open(py, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        fut = [l for l in lines if l.strip().startswith(\"from __future__\")]\n",
    "        oth = [l for l in lines if l not in fut]\n",
    "        with open(py, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(fut + oth)\n",
    "\n",
    "for m in [\"acc_env\", \"attacks\"]:\n",
    "    ensure_py(m)\n",
    "\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from acc_env import ACCEnv           # env with CBF clamp inside step()\n",
    "from attacks import FGSMAttack, OIAttack\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import numpy as np, math\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd08a46-9fd7-48f6-9ba8-396bdef10df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[demo] Loaded acc_env module from: /Users/lucylikesphotography/Documents/GitHub/PPO-and-Adversarial-Attack/PPO and Adversarial Attack/acc_env.py\n",
      "[demo] Constructing env from acc_env.ACCEnv class\n",
      "[demo] No attack.py detected â€” will use built-in FGSM/OIA.\n",
      "[demo] Loading VecNormalize from: runs/ppo_baseline/vecnormalize.pkl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Missing model at runs/ppo_baseline/best_model.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 390\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# =================== end demo_autodetect.py ===================\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 325\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 325\u001b[0m     model, vec_env \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_and_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLOGDIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     attack_fns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfgsm\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_attack_fn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfgsm\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moia\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_attack_fn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moia\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[1;32m    327\u001b[0m     results \u001b[38;5;241m=\u001b[39m {k: {} \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m attack_fns}\n",
      "Cell \u001b[0;32mIn[35], line 189\u001b[0m, in \u001b[0;36mload_model_and_env\u001b[0;34m(logdir)\u001b[0m\n\u001b[1;32m    186\u001b[0m     vec_env\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing model at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    190\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(model_path, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m    191\u001b[0m model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(DEVICE); model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Missing model at runs/ppo_baseline/best_model.zip"
     ]
    }
   ],
   "source": [
    "# ===================== demo_autodetect.py =====================\n",
    "import os, sys, inspect, importlib, importlib.util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "def _find_latest_model(logdir: str) -> Optional[str]:\n",
    "    \"\"\"Search recursively for .zip models under logdir and return the newest by mtime.\"\"\"\n",
    "    p = Path(logdir)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    zips = sorted(p.rglob(\"*.zip\"), key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "    return str(zips[0]) if zips else None\n",
    "\n",
    "def _find_vecnormalize(logdir: str) -> Optional[str]:\n",
    "    \"\"\"Look for vecnormalize.pkl under logdir (top-level or recursively).\"\"\"\n",
    "    p = Path(logdir)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    # common names/locations\n",
    "    candidates = list(p.rglob(\"vecnormalize.pkl\")) + list(p.glob(\"vecnormalize.pkl\"))\n",
    "    return str(candidates[0]) if candidates else None\n",
    "\n",
    "# -------------------------- USER CONFIG --------------------------\n",
    "LOGDIR = \"runs/ppo_baseline\"         # contains best_model.zip and vecnormalize.pkl\n",
    "MODEL_PATH = os.path.join(LOGDIR, \"best_model.zip\")\n",
    "VEC_PATH   = os.path.join(LOGDIR, \"vecnormalize.pkl\")\n",
    "\n",
    "N_EVAL_EPISODES = 100\n",
    "MAX_EPISODE_LEN = 1000\n",
    "EPSILONS = [0.0, 0.005, 0.01, 0.02]\n",
    "SEED = 0\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# ---------- Robustly import acc_env.py, even if no make_acc_env ----------\n",
    "def _import_acc_env_module():\n",
    "    # Try normal import first\n",
    "    try:\n",
    "        import acc_env as mod\n",
    "        return mod\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try by absolute path next to this script\n",
    "    here = os.path.abspath(os.path.dirname(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "    cand = os.path.join(here, \"acc_env.py\")\n",
    "    if not os.path.exists(cand):\n",
    "        raise ImportError(\"Cannot find acc_env.py; place demo_autodetect.py in the same folder as acc_env.py.\")\n",
    "    spec = importlib.util.spec_from_file_location(\"acc_env_autoload\", cand)\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[\"acc_env_autoload\"] = mod\n",
    "    spec.loader.exec_module(mod)  # type: ignore\n",
    "    return mod\n",
    "\n",
    "acc_env_mod = _import_acc_env_module()\n",
    "print(\"[demo] Loaded acc_env module from:\", getattr(acc_env_mod, \"__file__\", \"<memory>\"))\n",
    "\n",
    "# Build a make_acc_env wrapper no matter what shapes acc_env provides\n",
    "def _resolve_env_builder(mod):\n",
    "    # 1) If module already has make_acc_env, use it\n",
    "    if hasattr(mod, \"make_acc_env\") and inspect.isfunction(getattr(mod, \"make_acc_env\")):\n",
    "        print(\"[demo] Using acc_env.make_acc_env(...)\")\n",
    "        return getattr(mod, \"make_acc_env\")\n",
    "\n",
    "    # 2) If module exposes ACCEnv class, build a factory around it\n",
    "    if hasattr(mod, \"ACCEnv\") and inspect.isclass(getattr(mod, \"ACCEnv\")):\n",
    "        ACCEnv = getattr(mod, \"ACCEnv\")\n",
    "        print(\"[demo] Constructing env from acc_env.ACCEnv class\")\n",
    "        def make_acc_env(normalize_obs=False, seed=None):\n",
    "            # Try several common constructor signatures\n",
    "            tried = []\n",
    "            for kwargs in [\n",
    "                {},  # no-arg\n",
    "                {\"normalize_obs\": normalize_obs},\n",
    "                {\"seed\": seed},\n",
    "                {\"normalize_obs\": normalize_obs, \"seed\": seed},\n",
    "            ]:\n",
    "                try:\n",
    "                    env = ACCEnv(**{k:v for k,v in kwargs.items() if v is not None})\n",
    "                    return env\n",
    "                except Exception as e:\n",
    "                    tried.append((kwargs, str(e)))\n",
    "            raise RuntimeError(f\"Could not construct ACCEnv with common kwargs. Tried: {tried}\")\n",
    "        return make_acc_env\n",
    "\n",
    "    # 3) Common builder names: make_env / create_env / build_env\n",
    "    for name in (\"make_env\", \"create_env\", \"build_env\"):\n",
    "        if hasattr(mod, name) and inspect.isfunction(getattr(mod, name)):\n",
    "            fn = getattr(mod, name)\n",
    "            print(f\"[demo] Using acc_env.{name}(...) as builder\")\n",
    "            def make_acc_env(normalize_obs=False, seed=None):\n",
    "                # Try with/without kwargs\n",
    "                tried = []\n",
    "                for kwargs in [{}, {\"normalize_obs\": normalize_obs}, {\"seed\": seed},\n",
    "                               {\"normalize_obs\": normalize_obs, \"seed\": seed}]:\n",
    "                    try:\n",
    "                        env = fn(**{k:v for k,v in kwargs.items() if v is not None})\n",
    "                        return env\n",
    "                    except Exception as e:\n",
    "                        tried.append((kwargs, str(e)))\n",
    "                raise RuntimeError(f\"Could not construct env via {name} with common kwargs. Tried: {tried}\")\n",
    "            return make_acc_env\n",
    "\n",
    "    raise ImportError(\n",
    "        \"acc_env.py does not expose make_acc_env, ACCEnv, or a builder named make_env/create_env/build_env.\\n\"\n",
    "        \"Please either:\\n\"\n",
    "        \"  (A) add in acc_env.py:\\n\"\n",
    "        \"      def make_acc_env(normalize_obs=False, seed=None):\\n\"\n",
    "        \"          return ACCEnv(...)\\n\"\n",
    "        \"  or (B) rename your existing creator to one of the above.\"\n",
    "    )\n",
    "\n",
    "make_acc_env = _resolve_env_builder(acc_env_mod)\n",
    "\n",
    "# ---------- Optionally import your attack.py (fgsm_attack/oia_attack) ----------\n",
    "attack_module = None\n",
    "try:\n",
    "    import attack as attack_module\n",
    "    print(\"[demo] Imported attack.py\")\n",
    "except Exception:\n",
    "    print(\"[demo] No attack.py detected â€” will use built-in FGSM/OIA.\")\n",
    "\n",
    "# ---------- Env factory: MUST return RAW gym.Env (unwrap if VecEnv sneaks in) ----------\n",
    "def make_eval_env_factory(normalize_obs=False, seed=0):\n",
    "    def _init():\n",
    "        env = make_acc_env(normalize_obs=normalize_obs, seed=seed)\n",
    "\n",
    "        # If someone returned a VecEnv, unwrap to the underlying raw env\n",
    "        if isinstance(env, VecEnv):\n",
    "            print(\"[demo] WARN: builder returned a VecEnv; unwrapping to raw env.\")\n",
    "            raw = env.envs[0].unwrapped\n",
    "            try:\n",
    "                env.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "            env = raw\n",
    "\n",
    "        assert isinstance(env, gym.Env), (\n",
    "            \"make_eval_env_factory must return a RAW Gymnasium env. \"\n",
    "            \"Edit acc_env to return ACCEnv(...), not DummyVecEnv([...]).\"\n",
    "        )\n",
    "\n",
    "        # Seed\n",
    "        try:\n",
    "            env.reset(seed=seed)\n",
    "        except TypeError:\n",
    "            try: env.seed(seed)\n",
    "            except Exception: pass\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Guard\n",
    "_test = make_eval_env_factory(normalize_obs=False, seed=SEED)\n",
    "_tmp = _test()\n",
    "assert isinstance(_tmp, gym.Env) and not isinstance(_tmp, VecEnv), \"Factory returned a VecEnv â€” fix acc_env.\"\n",
    "try: _tmp.close()\n",
    "except Exception: pass\n",
    "\n",
    "# ---------- Load model + VecNormalize ----------\n",
    "def load_model_and_env(logdir: str):\n",
    "    model_path = os.path.join(logdir, \"best_model.zip\")\n",
    "    vec_path   = os.path.join(logdir, \"vecnormalize.pkl\")\n",
    "\n",
    "    base_raw = DummyVecEnv([make_eval_env_factory(normalize_obs=False, seed=SEED)])\n",
    "\n",
    "    if os.path.exists(vec_path):\n",
    "        print(f\"[demo] Loading VecNormalize from: {vec_path}\")\n",
    "        vec_env = VecNormalize.load(vec_path, base_raw)\n",
    "        vec_env.training = False\n",
    "        vec_env.norm_reward = False\n",
    "    else:\n",
    "        print(\"[demo] No VecNormalize found; creating fresh stats (ensure consistent with training!)\")\n",
    "        base_norm = DummyVecEnv([make_eval_env_factory(normalize_obs=True, seed=SEED)])\n",
    "        vec_env = VecNormalize(base_norm, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "        vec_env.training = False\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Missing model at {model_path}\")\n",
    "    model = PPO.load(model_path, device=DEVICE)\n",
    "    model.policy.to(DEVICE); model.policy.eval()\n",
    "    return model, vec_env\n",
    "\n",
    "# ---------- SB3 policy/value access ----------\n",
    "def _policy_mean_actions(model: PPO, obs_t: torch.Tensor) -> torch.Tensor:\n",
    "    p = model.policy\n",
    "    try:\n",
    "        feats = p.extract_features(obs_t)\n",
    "        return p.action_net(feats)\n",
    "    except Exception:\n",
    "        lat_pi, _ = p.mlp_extractor(obs_t)\n",
    "        return p.action_net(lat_pi)\n",
    "\n",
    "def _value_of(model: PPO, obs_t: torch.Tensor) -> torch.Tensor:\n",
    "    p = model.policy\n",
    "    try:\n",
    "        _, lat_vf = p.mlp_extractor(obs_t)\n",
    "        return p.value_net(lat_vf)\n",
    "    except Exception:\n",
    "        lat_pi, lat_vf = p._get_latent(obs_t)\n",
    "        return p.value_net(lat_vf)\n",
    "\n",
    "def _as_t(obs_np):\n",
    "    t = torch.as_tensor(obs_np, device=DEVICE, dtype=torch.float32)\n",
    "    if t.dim() == 1: t = t.unsqueeze(0)\n",
    "    t.requires_grad_(True)\n",
    "    return t\n",
    "\n",
    "# ---------- Built-in attacks if attack.py missing ----------\n",
    "def _fgsm_on_policy_normalized(obs_np, epsilon, model: PPO):\n",
    "    obs_t = _as_t(obs_np)\n",
    "    obj = _policy_mean_actions(model, obs_t).mean()\n",
    "    model.policy.zero_grad()\n",
    "    if obs_t.grad is not None:\n",
    "        obs_t.grad.detach_(); obs_t.grad.zero_()\n",
    "    obj.backward()\n",
    "    grad = obs_t.grad.detach().cpu().numpy()\n",
    "    return (obs_np.reshape(grad.shape) + epsilon * np.sign(grad)).squeeze()\n",
    "\n",
    "def _oia_on_critic_normalized(obs_np, epsilon, model: PPO):\n",
    "    obs_t = _as_t(obs_np)\n",
    "    obj = _value_of(model, obs_t).mean()\n",
    "    model.policy.zero_grad()\n",
    "    if obs_t.grad is not None:\n",
    "        obs_t.grad.detach_(); obs_t.grad.zero_()\n",
    "    obj.backward()\n",
    "    grad = obs_t.grad.detach().cpu().numpy()\n",
    "    return (obs_np.reshape(grad.shape) + epsilon * np.sign(grad)).squeeze()\n",
    "\n",
    "def get_attack_fn(name: str):\n",
    "    if attack_module is not None:\n",
    "        if name == \"fgsm\" and hasattr(attack_module, \"fgsm_attack\"):\n",
    "            return attack_module.fgsm_attack\n",
    "        if name == \"oia\" and hasattr(attack_module, \"oia_attack\"):\n",
    "            return attack_module.oia_attack\n",
    "    return _fgsm_on_policy_normalized if name == \"fgsm\" else (_oia_on_critic_normalized if name == \"oia\" else None)\n",
    "\n",
    "# ---------- CBF clamp (match your training params here if different) ----------\n",
    "def cbf_safety_clamp(action, raw_obs):\n",
    "    # raw_obs = [delta_x, delta_v, v]\n",
    "    delta_x = float(raw_obs[0]); delta_v = float(raw_obs[1]); v = float(raw_obs[2])\n",
    "    T_h = 1.5; dt = 0.1\n",
    "    a_min, a_max = -3.5, 2.0\n",
    "    a_max_safe = (delta_x - T_h * v + delta_v * dt) / (T_h * dt)\n",
    "    safe_upper = max(min(a_max, a_max_safe), a_min)\n",
    "    return float(np.clip(action, a_min, safe_upper))\n",
    "\n",
    "# ---------- Evaluation ----------\n",
    "def evaluate(model: PPO, vec_env: VecNormalize, attack_fn, epsilon: float,\n",
    "             n_episodes: int = 10, max_steps: int = 1000, seed: int = 0):\n",
    "    collisions = 0\n",
    "    returns, lengths, trajectories = [], [], []\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        obs = vec_env.reset()\n",
    "        ep_ret, ep_len = 0.0, 0\n",
    "        traj = {\"delta_x\": [], \"actions\": [], \"attacks\": [], \"raw_obs\": []}\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            obs_agent = obs[0] if (isinstance(obs, np.ndarray) and obs.ndim == 2 and obs.shape[0] == 1) else obs\n",
    "\n",
    "            # Attack on normalized obs\n",
    "            if attack_fn is not None and epsilon > 0.0:\n",
    "                attacked = attack_fn(obs_agent, epsilon, model)\n",
    "            else:\n",
    "                attacked = obs_agent\n",
    "\n",
    "            action, _ = model.predict(attacked, deterministic=True)\n",
    "            action = float(np.array(action).squeeze())\n",
    "\n",
    "            # Unnormalize for CBF\n",
    "            if isinstance(vec_env, VecNormalize):\n",
    "                mean = vec_env.obs_rms.mean; std = np.sqrt(vec_env.obs_rms.var + 1e-8)\n",
    "                raw_obs = obs_agent * std + mean\n",
    "            else:\n",
    "                raw_obs = obs_agent\n",
    "\n",
    "            a_safe = cbf_safety_clamp(action, raw_obs)\n",
    "            obs_next, reward, done, info = vec_env.step(np.array([[a_safe]], dtype=np.float32))\n",
    "            next_agent_obs = obs_next[0] if (isinstance(obs_next, np.ndarray) and obs_next.ndim == 2 and obs_next.shape[0] == 1) else obs_next\n",
    "\n",
    "            # Unnormalize next for logging\n",
    "            if isinstance(vec_env, VecNormalize):\n",
    "                raw_next = next_agent_obs * std + mean\n",
    "            else:\n",
    "                raw_next = next_agent_obs\n",
    "\n",
    "            if raw_next[0] <= 0.0:\n",
    "                collisions += 1\n",
    "\n",
    "            traj[\"delta_x\"].append(float(raw_next[0]))\n",
    "            traj[\"actions\"].append(float(a_safe))\n",
    "            traj[\"raw_obs\"].append(np.array(raw_next, dtype=float))\n",
    "            traj[\"attacks\"].append(float(np.linalg.norm((next_agent_obs - obs_agent).ravel())))\n",
    "\n",
    "            ep_ret += float(reward[0] if isinstance(reward, np.ndarray) else reward)\n",
    "            ep_len += 1\n",
    "            obs = obs_next\n",
    "\n",
    "            if (isinstance(done, (list, np.ndarray)) and done[0]) or (isinstance(done, (bool, np.bool_)) and done):\n",
    "                break\n",
    "\n",
    "        returns.append(ep_ret); lengths.append(ep_len); trajectories.append(traj)\n",
    "\n",
    "    return {\n",
    "        \"mean_return\": float(np.mean(returns)) if returns else 0.0,\n",
    "        \"std_return\":  float(np.std(returns))  if returns else 0.0,\n",
    "        \"mean_length\": float(np.mean(lengths)) if lengths else 0.0,\n",
    "        \"collision_rate\": collisions / max(1, n_episodes),\n",
    "        \"trajectories\": trajectories\n",
    "    }\n",
    "\n",
    "# ---------- Run + plots ----------\n",
    "def main():\n",
    "    model, vec_env = load_model_and_env(LOGDIR)\n",
    "    attack_fns = {\"baseline\": None, \"fgsm\": get_attack_fn(\"fgsm\"), \"oia\": get_attack_fn(\"oia\")}\n",
    "    results = {k: {} for k in attack_fns}\n",
    "\n",
    "    for atype, fn in attack_fns.items():\n",
    "        print(f\"[demo] Running: {atype}\")\n",
    "        for eps in EPSILONS:\n",
    "            if atype == \"baseline\" and eps != 0.0: continue\n",
    "            print(f\"  eps={eps} ...\", end=\"\", flush=True)\n",
    "            res = evaluate(model, vec_env, fn, eps, n_episodes=N_EVAL_EPISODES, max_steps=MAX_EPISODE_LEN, seed=SEED)\n",
    "            results[atype][eps] = res\n",
    "            print(f\" done (ret={res['mean_return']:.3f}, coll={res['collision_rate']:.3f})\")\n",
    "\n",
    "    # 1) Headway trajectories\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for atype in [\"baseline\",\"fgsm\",\"oia\"]:\n",
    "        eps = 0.0 if atype==\"baseline\" else (0.01 if 0.01 in results[atype] else sorted(results[atype].keys())[0])\n",
    "        traj = results[atype][eps][\"trajectories\"][0]\n",
    "        plt.plot(traj[\"delta_x\"], label=f\"{atype} (eps={eps})\")\n",
    "    plt.xlabel(\"Time step\"); plt.ylabel(\"Headway Î”x (raw)\")\n",
    "    plt.title(\"Example headway trajectories\")\n",
    "    plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 2) Stealth proxy vs epsilon\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for atype in [\"fgsm\",\"oia\"]:\n",
    "        xs, ys = [], []\n",
    "        for eps in EPSILONS:\n",
    "            if eps == 0.0 or eps not in results[atype]: continue\n",
    "            trajs = results[atype][eps][\"trajectories\"]\n",
    "            per_ep = [np.array(tr[\"attacks\"]).mean() if tr[\"attacks\"] else 0.0 for tr in trajs]\n",
    "            xs.append(eps); ys.append(float(np.mean(per_ep)))\n",
    "        plt.plot(xs, ys, marker='o', label=atype)\n",
    "    plt.xlabel(\"epsilon (normalized)\"); plt.ylabel(\"Mean per-step perturbation norm\")\n",
    "    plt.title(\"Stealth vs epsilon\"); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 3) Collision rate bars\n",
    "    labels, vals = [], []\n",
    "    for atype in [\"baseline\",\"fgsm\",\"oia\"]:\n",
    "        eps = 0.0 if atype==\"baseline\" else (0.01 if 0.01 in results[atype] else sorted(results[atype].keys())[0])\n",
    "        labels.append(f\"{atype}\\n(eps={eps})\"); vals.append(results[atype][eps][\"collision_rate\"])\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(labels, vals)\n",
    "    plt.ylabel(\"Collision rate\"); plt.title(\"Collision rate by condition\")\n",
    "    plt.grid(axis='y'); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 4) Mean return bars\n",
    "    labels, vals = [], []\n",
    "    for atype in [\"baseline\",\"fgsm\",\"oia\"]:\n",
    "        eps = 0.0 if atype==\"baseline\" else (0.01 if 0.01 in results[atype] else sorted(results[atype].keys())[0])\n",
    "        labels.append(f\"{atype}\\n(eps={eps})\"); vals.append(results[atype][eps][\"mean_return\"])\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(labels, vals)\n",
    "    plt.ylabel(\"Mean return\"); plt.title(\"Mean return by condition\")\n",
    "    plt.grid(axis='y'); plt.tight_layout(); plt.show()\n",
    "\n",
    "    print(\"\\n[demo] Summary:\")\n",
    "    for atype in results:\n",
    "        for eps, res in results[atype].items():\n",
    "            print(f\"  {atype:8s} eps={eps:<5}: ret={res['mean_return']:.3f} Â± {res['std_return']:.3f}, \"\n",
    "                  f\"len={res['mean_length']:.1f}, coll={res['collision_rate']:.3f}\")\n",
    "    try: vec_env.close()\n",
    "    except Exception: pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# =================== end demo_autodetect.py ===================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
