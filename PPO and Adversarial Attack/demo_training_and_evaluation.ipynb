{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c033ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /mnt/data/ppo_acc_attack\n",
      "Files:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/ppo_acc_attack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject root:\u001b[39m\u001b[38;5;124m'\u001b[39m, proj_root)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiles:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproj_root\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/ppo_acc_attack'"
     ]
    }
   ],
   "source": [
    "# Setup: (run this once in your environment)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import os, sys, pprint\n",
    "# Ensure project path is importable\n",
    "proj_root = os.path.abspath('/mnt/data/ppo_acc_attack')\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "\n",
    "print('Project root:', proj_root)\n",
    "print('Files:')\n",
    "print('\\n'.join(sorted(os.listdir(proj_root))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ea430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper wrappers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from acc_env import ACCEnv\n",
    "from attacks import FGSMAttack, OIAttack\n",
    "import os, csv, json\n",
    "\n",
    "# Simple plotting helper (one plot per cell as required)\n",
    "def plot_traj(traj, title, out_png=None):\n",
    "    t = np.arange(len(traj['Δx']))\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['Δx'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('Δx (m)'); plt.title(title + ' — headway (Δx)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_dx.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['v'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('v (m/s)'); plt.title(title + ' — ego speed (v)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_v.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['a'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('a (m/s^2)'); plt.title(title + ' — acceleration (a)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_a.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print('Imports OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment factory (vectorized-friendly)\n",
    "\n",
    "def make_env(brake_profile=False, normalize_obs=True, seed=0):\n",
    "    def _thunk():\n",
    "        return ACCEnv(brake_profile=brake_profile, normalize_obs=normalize_obs, seed=seed)\n",
    "    return _thunk\n",
    "\n",
    "# Quick smoke test\n",
    "env = make_env(brake_profile=True, normalize_obs=True)()\n",
    "obs, info = env.reset()\n",
    "print('Initial observation:', obs)\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Action space:', env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cell - adjust TOTAL_STEPS if you want a fast demo\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "TOTAL_STEPS = 200_000  # paper suggests >200k; change to 10_000 for quick tests\n",
    "LOGDIR = 'runs/ppo_demo'\n",
    "\n",
    "os.makedirs(LOGDIR, exist_ok=True)\n",
    "\n",
    "# Create VecNormalize-wrapped env (single-threaded for simplicity)\n",
    "env = DummyVecEnv([make_env(brake_profile=False, normalize_obs=True)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=1.0)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1, seed=0,\n",
    "            n_steps=1024, batch_size=128, learning_rate=3e-4, gamma=0.99,\n",
    "            gae_lambda=0.95, clip_range=0.2, ent_coef=0.0)\n",
    "new_logger = configure(LOGDIR, ['stdout','csv','tensorboard'])\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "print('Starting training for', TOTAL_STEPS, 'steps...')\n",
    "# Uncomment the following lines to actually run training\n",
    "# model.learn(total_timesteps=TOTAL_STEPS)\n",
    "# model.save(os.path.join(LOGDIR,'ppo_acc'))\n",
    "# env.save(os.path.join(LOGDIR,'vecnormalize.pkl'))\n",
    "\n",
    "print('Training cell prepared (learn call is commented out to avoid long runs).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c62fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation utilities\n",
    "import numpy as np\n",
    "\n",
    "def load_model_and_env(logdir: str):\n",
    "    env = DummyVecEnv([make_env(brake_profile=True, normalize_obs=True)])\n",
    "    env = VecNormalize.load(os.path.join(logdir, 'vecnormalize.pkl'), env)\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "    model = PPO.load(os.path.join(logdir, 'ppo_acc'))\n",
    "    return model, env\n",
    "\n",
    "def run_episode(model, env, attack=None, eps=0.01, render_traj=False):\n",
    "    obs = env.reset()[0]\n",
    "    traj = {k: [] for k in ['Δx','v','a','r']}\n",
    "    total_r = 0.0\n",
    "    collisions = 0\n",
    "    rmse_accum = 0.0\n",
    "    rmse_count = 0\n",
    "\n",
    "    # Wrap model with attack if requested\n",
    "    atk = None\n",
    "    if attack == 'fgsm':\n",
    "        atk = FGSMAttack(model, epsilon=eps, device='cpu')\n",
    "    elif attack == 'oia':\n",
    "        atk = OIAttack(model, epsilon=eps, device='cpu')\n",
    "\n",
    "    while True:\n",
    "        if atk is None:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs_in = obs\n",
    "        else:\n",
    "            action, obs_in = atk.act(obs)\n",
    "\n",
    "        obs, reward, term, trunc, info = env.step(action)\n",
    "        total_r += reward[0] if isinstance(reward, np.ndarray) else reward\n",
    "        traj['Δx'].append(info[0]['Δx'] if isinstance(info, list) else info['Δx'])\n",
    "        traj['v'].append(info[0]['v'] if isinstance(info, list) else info['v'])\n",
    "        traj['a'].append(info[0]['a'] if isinstance(info, list) else info['a'])\n",
    "        traj['r'].append(reward[0] if isinstance(reward, np.ndarray) else reward)\n",
    "\n",
    "        if atk is not None:\n",
    "            diff = (obs_in - obs)\n",
    "            rmse_accum += float((diff**2).mean())\n",
    "            rmse_count += 1\n",
    "\n",
    "        done = bool(term) or bool(trunc)\n",
    "        if term:\n",
    "            collisions = 1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    jerk = np.mean(np.abs(np.diff(traj['a']))) if len(traj['a']) > 1 else 0.0\n",
    "    rmse = np.sqrt(rmse_accum / max(1, rmse_count))\n",
    "    return {'return': total_r, 'collision': collisions, 'jerk': jerk, 'rmse': rmse, 'traj': traj}\n",
    "\n",
    "def eval_many(model, env, which: str | None, episodes:int=20, eps=0.01, out_prefix='artifacts'):\n",
    "    atk = 'none' if which is None else which\n",
    "    rets, cols, jerks, rmses = [], [], [], []\n",
    "    sample_traj = None\n",
    "    for ep in range(episodes):\n",
    "        res = run_episode(model, env, attack=which, eps=eps)\n",
    "        rets.append(res['return'])\n",
    "        cols.append(res['collision'])\n",
    "        jerks.append(res['jerk'])\n",
    "        rmses.append(res['rmse'])\n",
    "        if sample_traj is None:\n",
    "            sample_traj = res['traj']\n",
    "    avg = {\n",
    "        'avg_return': float(np.mean(rets)),\n",
    "        'collision_rate': float(np.mean(cols)),\n",
    "        'avg_jerk': float(np.mean(jerks)),\n",
    "        'avg_rmse': float(np.mean(rmses)),\n",
    "    }\n",
    "    os.makedirs(out_prefix, exist_ok=True)\n",
    "    out_csv = os.path.join(out_prefix, f\"metrics_{atk}.csv\")\n",
    "    with open(out_csv, 'w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['metric','value'])\n",
    "        for k,v in avg.items():\n",
    "            w.writerow([k,v])\n",
    "    if sample_traj is not None:\n",
    "        plot_traj(sample_traj, f'{atk.upper()} sample episode', os.path.join(out_prefix, f'{atk}_traj.png'))\n",
    "    print(f\"{atk}: {avg}\")\n",
    "    return avg\n",
    "\n",
    "print('Evaluation functions prepared')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
