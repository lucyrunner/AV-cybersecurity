{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57555571",
   "metadata": {},
   "source": [
    "\n",
    "# Demo: Train PPO on ACCEnv and Evaluate FGSM / OIA Attacks\n",
    "\n",
    "This notebook follows the paper's implementation steps:\n",
    "\n",
    "1. Build and inspect the `ACCEnv` environment\n",
    "2. Train a PPO agent (with `VecNormalize`)\n",
    "3. Evaluate baseline performance (with safety filter active)\n",
    "4. Implement FGSM & OIA attack wrappers and evaluate under attack\n",
    "5. Compare metrics and plot trajectories\n",
    "\n",
    "**Notes:** The heavy training steps are provided as runnable cells but are _not executed_ by this notebook creation step. Adjust `TOTAL_STEPS` before running if you want a faster demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c033ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: (run this once in your environment)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import os, sys, pprint\n",
    "# Ensure project path is importable\n",
    "proj_root = os.path.abspath('/mnt/data/ppo_acc_attack')\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "\n",
    "print('Project root:', proj_root)\n",
    "print('Files:')\n",
    "print('\\n'.join(sorted(os.listdir(proj_root))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ea430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper wrappers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from acc_env import ACCEnv\n",
    "from attacks import FGSMAttack, OIAttack\n",
    "import os, csv, json\n",
    "\n",
    "# Simple plotting helper (one plot per cell as required)\n",
    "def plot_traj(traj, title, out_png=None):\n",
    "    t = np.arange(len(traj['Δx']))\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['Δx'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('Δx (m)'); plt.title(title + ' — headway (Δx)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_dx.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['v'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('v (m/s)'); plt.title(title + ' — ego speed (v)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_v.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t, traj['a'])\n",
    "    plt.xlabel('t (steps)'); plt.ylabel('a (m/s^2)'); plt.title(title + ' — acceleration (a)')\n",
    "    if out_png: plt.savefig(out_png.replace('.png','_a.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print('Imports OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment factory (vectorized-friendly)\n",
    "\n",
    "def make_env(brake_profile=False, normalize_obs=True, seed=0):\n",
    "    def _thunk():\n",
    "        return ACCEnv(brake_profile=brake_profile, normalize_obs=normalize_obs, seed=seed)\n",
    "    return _thunk\n",
    "\n",
    "# Quick smoke test\n",
    "env = make_env(brake_profile=True, normalize_obs=True)()\n",
    "obs, info = env.reset()\n",
    "print('Initial observation:', obs)\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Action space:', env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cell - adjust TOTAL_STEPS if you want a fast demo\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "TOTAL_STEPS = 200_000  # paper suggests >200k; change to 10_000 for quick tests\n",
    "LOGDIR = 'runs/ppo_demo'\n",
    "\n",
    "os.makedirs(LOGDIR, exist_ok=True)\n",
    "\n",
    "# Create VecNormalize-wrapped env (single-threaded for simplicity)\n",
    "env = DummyVecEnv([make_env(brake_profile=False, normalize_obs=True)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=1.0)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1, seed=0,\n",
    "            n_steps=1024, batch_size=128, learning_rate=3e-4, gamma=0.99,\n",
    "            gae_lambda=0.95, clip_range=0.2, ent_coef=0.0)\n",
    "new_logger = configure(LOGDIR, ['stdout','csv','tensorboard'])\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "print('Starting training for', TOTAL_STEPS, 'steps...')\n",
    "# Uncomment the following lines to actually run training\n",
    "# model.learn(total_timesteps=TOTAL_STEPS)\n",
    "# model.save(os.path.join(LOGDIR,'ppo_acc'))\n",
    "# env.save(os.path.join(LOGDIR,'vecnormalize.pkl'))\n",
    "\n",
    "print('Training cell prepared (learn call is commented out to avoid long runs).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c62fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation utilities\n",
    "import numpy as np\n",
    "\n",
    "def load_model_and_env(logdir: str):\n",
    "    env = DummyVecEnv([make_env(brake_profile=True, normalize_obs=True)])\n",
    "    env = VecNormalize.load(os.path.join(logdir, 'vecnormalize.pkl'), env)\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "    model = PPO.load(os.path.join(logdir, 'ppo_acc'))\n",
    "    return model, env\n",
    "\n",
    "def run_episode(model, env, attack=None, eps=0.01, render_traj=False):\n",
    "    obs = env.reset()[0]\n",
    "    traj = {k: [] for k in ['Δx','v','a','r']}\n",
    "    total_r = 0.0\n",
    "    collisions = 0\n",
    "    rmse_accum = 0.0\n",
    "    rmse_count = 0\n",
    "\n",
    "    # Wrap model with attack if requested\n",
    "    atk = None\n",
    "    if attack == 'fgsm':\n",
    "        atk = FGSMAttack(model, epsilon=eps, device='cpu')\n",
    "    elif attack == 'oia':\n",
    "        atk = OIAttack(model, epsilon=eps, device='cpu')\n",
    "\n",
    "    while True:\n",
    "        if atk is None:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs_in = obs\n",
    "        else:\n",
    "            action, obs_in = atk.act(obs)\n",
    "\n",
    "        obs, reward, term, trunc, info = env.step(action)\n",
    "        total_r += reward[0] if isinstance(reward, np.ndarray) else reward\n",
    "        traj['Δx'].append(info[0]['Δx'] if isinstance(info, list) else info['Δx'])\n",
    "        traj['v'].append(info[0]['v'] if isinstance(info, list) else info['v'])\n",
    "        traj['a'].append(info[0]['a'] if isinstance(info, list) else info['a'])\n",
    "        traj['r'].append(reward[0] if isinstance(reward, np.ndarray) else reward)\n",
    "\n",
    "        if atk is not None:\n",
    "            diff = (obs_in - obs)\n",
    "            rmse_accum += float((diff**2).mean())\n",
    "            rmse_count += 1\n",
    "\n",
    "        done = bool(term) or bool(trunc)\n",
    "        if term:\n",
    "            collisions = 1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    jerk = np.mean(np.abs(np.diff(traj['a']))) if len(traj['a']) > 1 else 0.0\n",
    "    rmse = np.sqrt(rmse_accum / max(1, rmse_count))\n",
    "    return {'return': total_r, 'collision': collisions, 'jerk': jerk, 'rmse': rmse, 'traj': traj}\n",
    "\n",
    "def eval_many(model, env, which: str | None, episodes:int=20, eps=0.01, out_prefix='artifacts'):\n",
    "    atk = 'none' if which is None else which\n",
    "    rets, cols, jerks, rmses = [], [], [], []\n",
    "    sample_traj = None\n",
    "    for ep in range(episodes):\n",
    "        res = run_episode(model, env, attack=which, eps=eps)\n",
    "        rets.append(res['return'])\n",
    "        cols.append(res['collision'])\n",
    "        jerks.append(res['jerk'])\n",
    "        rmses.append(res['rmse'])\n",
    "        if sample_traj is None:\n",
    "            sample_traj = res['traj']\n",
    "    avg = {\n",
    "        'avg_return': float(np.mean(rets)),\n",
    "        'collision_rate': float(np.mean(cols)),\n",
    "        'avg_jerk': float(np.mean(jerks)),\n",
    "        'avg_rmse': float(np.mean(rmses)),\n",
    "    }\n",
    "    os.makedirs(out_prefix, exist_ok=True)\n",
    "    out_csv = os.path.join(out_prefix, f\"metrics_{atk}.csv\")\n",
    "    with open(out_csv, 'w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['metric','value'])\n",
    "        for k,v in avg.items():\n",
    "            w.writerow([k,v])\n",
    "    if sample_traj is not None:\n",
    "        plot_traj(sample_traj, f'{atk.upper()} sample episode', os.path.join(out_prefix, f'{atk}_traj.png'))\n",
    "    print(f\"{atk}: {avg}\")\n",
    "    return avg\n",
    "\n",
    "print('Evaluation functions prepared')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bba835",
   "metadata": {},
   "source": [
    "\n",
    " How to run a full experiment (instructions)\n",
    "\n",
    "1. Run the **Training cell** with `TOTAL_STEPS` set to 200000 (or reduce to 10000 for a quick smoke test). Uncomment the `model.learn(...)` and save lines.\n",
    "\n",
    "2. After training finishes, ensure the model files exist in the logdir (e.g., `runs/ppo_demo/ppo_acc.zip` and `vecnormalize.pkl`).\n",
    "\n",
    "3. Run the evaluation example:\n",
    "```python\n",
    "model, env = load_model_and_env('runs/ppo_demo')\n",
    "base = eval_many(model, env, None, episodes=20, eps=0.0)\n",
    "fgsm = eval_many(model, env, 'fgsm', episodes=20, eps=0.01)\n",
    "oia  = eval_many(model, env, 'oia', episodes=20, eps=0.01)\n",
    "```\n",
    "\n",
    "4. Compare `artifacts/metrics_none.csv`, `artifacts/metrics_fgsm.csv`, `artifacts/metrics_oia.csv` and the sample trajectory plots saved in `artifacts/`.\n",
    "\n",
    "The notebook provides a reproducible pipeline matching the paper's steps: environment, safety filter (already in ACCEnv), training with VecNormalize, FGSM & OIA wrappers, evaluation metrics, and trajectory plots.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
